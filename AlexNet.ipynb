{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import csv\n",
        "from numpy import asarray, save\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# load data separated into training and test set dataset\n",
        "(ds_train, ds_test), ds_info = tfds.load('stanford_dogs', split=['train', 'test'], shuffle_files=True, with_info=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "0Y1J14nuiKgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbFazRapkgG_",
        "outputId": "4b1d345c-9a0d-4dfc-b979-68e8b8c14efe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resize the images to fit the input for AlexNet (227x227)\n",
        "\n",
        "#____________________________________________________________________________________________________________________________\n",
        "# Resize the images to fit the input for AlexNet (227x227)\n",
        "\n",
        "# Training Set\n",
        "train_lst_imgs = []\n",
        "train_lst_labels = []\n",
        "\n",
        "print(\"The images will be resized now.\")\n",
        "\n",
        "kaggle_breeds = ('n02105162-malinois', 'n02094258-Norwich_terrier', 'n02102177-Welsh_springer_spaniel', 'n02086646-Blenheim_spaniel', 'n02086910-papillon', 'n02093256-Staffordshire_bullterrier', 'n02113624-toy_poodle', 'n02105056-groenendael', 'n02109961-Eskimo_dog', 'n02116738-African_hunting_dog', 'n02096177-cairn', 'n02096585-Boston_bull', 'n02100735-English_setter', 'n02102973-Irish_water_spaniel', 'n02099429-curly-coated_retriever', 'n02088364-beagle', 'n02101006-Gordon_setter', 'n02108089-boxer', 'n02097130-giant_schnauzer', 'n02112137-chow')\n",
        "\n",
        "for train in tfds.as_numpy(ds_train):  # example is `{'image': tf.Tensor, 'label': tf.Tensor}`\n",
        "    #print(list(example.keys()))\n",
        "\n",
        "    #resize the image to 227 x 227 because this is what AlexNet uses\n",
        "    #if you want it with padding:\n",
        "    #train_lst_imgs.append(tf.image.resize_with_pad(train[\"image\"], target_height=227, target_width=227))\n",
        "\n",
        "    #Do a subset of the first 20 dog breeds to make it run faster\n",
        "\n",
        "    if train[\"label\"] <= 20:\n",
        "        train_lst_imgs.append(np.array(tf.image.resize(train[\"image\"], (227, 227))))\n",
        "        label = train[\"label\"]\n",
        "        train_lst_labels.append(label)\n",
        "\n",
        "# Test Set\n",
        "test_lst_imgs = []\n",
        "test_lst_labels = []\n",
        "\n",
        "for test in tfds.as_numpy(ds_test):  # example is `{'image': tf.Tensor, 'label': tf.Tensor}`\n",
        "    #print(list(example.keys()))\n",
        "\n",
        "    #resize the image to 227 x 227 because this is what AlexNet uses\n",
        "\n",
        "    #Do a subset of the first 20 dog breeds to make it run faster\n",
        "    if test[\"label\"] <= 20:\n",
        "        test_lst_imgs.append(np.array(tf.image.resize(test[\"image\"], (227, 227))))\n",
        "        label = test[\"label\"]\n",
        "        test_lst_labels.append(label)\n",
        "\n",
        "\n",
        "\n",
        "#verify that all of the images/labels were transferred when they were resized\n",
        "print(\"The length of the training list of resized images is:\", len(train_lst_imgs))\n",
        "print(\"The length of the training list of labels is:\", len(train_lst_labels))\n",
        "\n",
        "print(\"The length of the test list of resized images is:\", len(test_lst_imgs))\n",
        "print(\"The length of the test list of labels is:\", len(test_lst_labels))\n",
        "\n",
        "print(type(train_lst_imgs),type(train_lst_labels))\n",
        "#____________________________________________________________________________________________________________________________\n",
        "\n",
        "# Convert into NumPy Arrays\n",
        "\n",
        "# this can take a while - in TF2.X, apparently it's slow to convert list of tensors to numpy.array\n",
        "x_train = np.array(train_lst_imgs) #images\n",
        "y_train = np.array(train_lst_labels) #labels\n",
        "\n",
        "\n",
        "x_test = np.array(test_lst_imgs) #images\n",
        "y_test = np.array(test_lst_labels) #labels\n",
        "\n",
        "print(\"The images shape after converting into NumPy arrays is: \",x_train.shape,\"\\nThe labels shape after converting into NumPy arrays is: \",y_train.shape)\n",
        "print(\"Their types are: \")\n",
        "print(type(x_train),type(y_train))\n",
        "\n",
        "\n",
        "#____________________________________________________________________________________________________________________________\n",
        "\n",
        "\n",
        "# Normalize the data\n",
        "\n",
        "# Training Set\n",
        "xn_train = x_train.astype(np.float32)\n",
        "yn_train = y_train.astype(np.int32)\n",
        "#xn_train = xn_train/255\n",
        "print(\"Training set images shape after normalization = \", xn_train.shape)\n",
        "\n",
        "\n",
        "# Test Set\n",
        "xn_test = x_test.astype(np.float32)\n",
        "yn_test = y_test.astype(np.int32)\n",
        "print(\"Test set images shape after normalization = \", xn_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "#____________________________________________________________________________________________________________________________\n",
        "\n",
        "\n",
        "print(\"The model will now be defined and compiled.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8O4njkwj_9E",
        "outputId": "09b0b111-75bb-4979-e8fd-1e6df4ab94dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The images will be resized now.\n",
            "The length of the training list of resized images is: 2100\n",
            "The length of the training list of labels is: 2100\n",
            "The length of the test list of resized images is: 1715\n",
            "The length of the test list of labels is: 1715\n",
            "<class 'list'> <class 'list'>\n",
            "The images shape after converting into NumPy arrays is:  (2100, 227, 227, 3) \n",
            "The labels shape after converting into NumPy arrays is:  (2100,)\n",
            "Their types are: \n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "Training set images shape after normalization =  (2100, 227, 227, 3)\n",
            "Test set images shape after normalization =  (1715, 227, 227, 3)\n",
            "The model will now be defined and compiled.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "\n",
        "# Import a few specific libraries/layers\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, Dropout\n",
        "\n",
        "model=Sequential()\n",
        "\n",
        "#1 conv layer\n",
        "model.add(Conv2D(filters=96,kernel_size=(11,11),strides=(4,4),padding=\"valid\",activation=\"relu\",input_shape=(227,227,3)))\n",
        "\n",
        "#1 max pool layer\n",
        "model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#2 conv layer\n",
        "model.add(Conv2D(filters=256,kernel_size=(5,5),strides=(1,1),padding=\"valid\",activation=\"relu\"))\n",
        "\n",
        "#2 max pool layer\n",
        "model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#3 conv layer\n",
        "model.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding=\"valid\",activation=\"relu\"))\n",
        "\n",
        "#4 conv layer\n",
        "model.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding=\"valid\",activation=\"relu\"))\n",
        "\n",
        "#5 conv layer\n",
        "model.add(Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding=\"valid\",activation=\"relu\"))\n",
        "\n",
        "#3 max pool layer\n",
        "model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "#1 dense layer\n",
        "model.add(Dense(4096,input_shape=(227,227,3),activation=\"relu\"))\n",
        "\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#2 dense layer\n",
        "model.add(Dense(4096,activation=\"relu\"))\n",
        "\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#3 dense layer\n",
        "model.add(Dense(1000,activation=\"relu\"))\n",
        "\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#output layer\n",
        "model.add(Dense(120,activation=\"softmax\"))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#____________________________________________________________________________________________________________________________\n",
        "\n",
        "# Compile the model\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "print(\"Model is compiled.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gu7NFknRlTCv",
        "outputId": "55555346-5440-4255-84c0-44a40829c090"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_5 (Conv2D)           (None, 55, 55, 96)        34944     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 27, 27, 96)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 27, 27, 96)        384       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 23, 23, 256)       614656    \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 11, 11, 256)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 11, 11, 256)       1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 9, 9, 384)         885120    \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 7, 7, 384)         1327488   \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 5, 5, 256)         884992    \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 2, 2, 256)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_8 (Bat  (None, 2, 2, 256)         1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 4096)              4198400   \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " batch_normalization_9 (Bat  (None, 4096)              16384     \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " batch_normalization_10 (Ba  (None, 4096)              16384     \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1000)              4097000   \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 1000)              0         \n",
            "                                                                 \n",
            " batch_normalization_11 (Ba  (None, 1000)              4000      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 120)               120120    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28983232 (110.56 MB)\n",
            "Trainable params: 28963632 (110.49 MB)\n",
            "Non-trainable params: 19600 (76.56 KB)\n",
            "_________________________________________________________________\n",
            "Model is compiled.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Now the model will be trained. This may take around 20-30 minutes depending on image class size and epoch size.\")\n",
        "# Train the model\n",
        "\n",
        "start = time.time()\n",
        "history = model.fit(xn_train, yn_train, epochs=100)\n",
        "end = time.time()\n",
        "total_time = end-start\n",
        "\n",
        "#____________________________________________________________________________________________________________________________\n",
        "\n",
        "# Convert the time from seconds\n",
        "\n",
        "def convert(seconds):\n",
        "    return time.strftime(\"%H:%M:%S\", time.gmtime(seconds))\n",
        "\n",
        "total_time = convert(total_time)\n",
        "\n",
        "#____________________________________________________________________________________________________________________________\n",
        "\n",
        "# Save the epoch accuracy data\n",
        "\n",
        "with open('output.csv','w') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(model.history.history['accuracy'])\n",
        "\n",
        "#____________________________________________________________________________________________________________________________\n",
        "\n",
        "# Evaluate the loss and accuracy\n",
        "\n",
        "la = []\n",
        "\n",
        "loss, accuracy = model.evaluate(xn_test, yn_test)\n",
        "\n",
        "print(\"Training Runtime: \", total_time)\n",
        "print(\"The Test Set Loss is: \", loss, \"\\nThe Test Set Accuracy is: \", accuracy)\n",
        "\n",
        "la.append(loss)\n",
        "la.append(accuracy)\n",
        "la.append(total_time)\n",
        "\n",
        "\n",
        "#____________________________________________________________________________________________________________________________\n",
        "\n",
        "# Predict values with the model\n",
        "\n",
        "pred = model.predict(xn_test)\n",
        "\n",
        "#____________________________________________________________________________________________________________________________\n",
        "\n",
        "# Download xn_test and yn_test to create images of the predicted and actual dog breed estimates\n",
        "\n",
        "#randomly select 9 images\n",
        "\n",
        "images = []\n",
        "actual = []\n",
        "pred_label = []\n",
        "\n",
        "for i in range(9):\n",
        "    r = np.random.randint( 0, xn_test.shape[0], 1)\n",
        "    images.append(xn_test[r[0]])\n",
        "    actual.append(yn_test[r[0]])\n",
        "    pred_label.append(yn_test[r[0]]*pred[r[0]][yn_test[r[0]]])\n",
        "\n",
        "save('images.npy', images)\n",
        "\n",
        "with open('pred_labels.csv','w') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(pred_label)\n",
        "\n",
        "with open('actual_labels.csv','w') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(actual)\n",
        "\n",
        "with open('test.csv','w') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(la)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Lh-nor3iX7q",
        "outputId": "3f32b355-92de-411e-f949-b9c5356da9c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now the model will be trained. This may take around 20-30 minutes depending on image class size and epoch size.\n",
            "Epoch 1/100\n",
            "66/66 [==============================] - 54s 775ms/step - loss: 4.7287 - accuracy: 0.0857\n",
            "Epoch 2/100\n",
            "66/66 [==============================] - 51s 770ms/step - loss: 3.9037 - accuracy: 0.1048\n",
            "Epoch 3/100\n",
            "66/66 [==============================] - 51s 770ms/step - loss: 3.4686 - accuracy: 0.1162\n",
            "Epoch 4/100\n",
            "66/66 [==============================] - 51s 775ms/step - loss: 3.2248 - accuracy: 0.1295\n",
            "Epoch 5/100\n",
            "66/66 [==============================] - 52s 783ms/step - loss: 3.0728 - accuracy: 0.1495\n",
            "Epoch 6/100\n",
            "66/66 [==============================] - 51s 776ms/step - loss: 2.9496 - accuracy: 0.1519\n",
            "Epoch 7/100\n",
            "66/66 [==============================] - 51s 775ms/step - loss: 2.9181 - accuracy: 0.1724\n",
            "Epoch 8/100\n",
            "66/66 [==============================] - 51s 779ms/step - loss: 2.7766 - accuracy: 0.1867\n",
            "Epoch 9/100\n",
            "66/66 [==============================] - 51s 774ms/step - loss: 2.7414 - accuracy: 0.1971\n",
            "Epoch 10/100\n",
            "66/66 [==============================] - 51s 773ms/step - loss: 2.6653 - accuracy: 0.2043\n",
            "Epoch 11/100\n",
            "66/66 [==============================] - 51s 778ms/step - loss: 2.5878 - accuracy: 0.2167\n",
            "Epoch 12/100\n",
            "66/66 [==============================] - 51s 771ms/step - loss: 2.5123 - accuracy: 0.2495\n",
            "Epoch 13/100\n",
            "66/66 [==============================] - 51s 773ms/step - loss: 2.3803 - accuracy: 0.2686\n",
            "Epoch 14/100\n",
            "66/66 [==============================] - 51s 775ms/step - loss: 2.3611 - accuracy: 0.2657\n",
            "Epoch 15/100\n",
            "66/66 [==============================] - 51s 771ms/step - loss: 2.2313 - accuracy: 0.3148\n",
            "Epoch 16/100\n",
            "66/66 [==============================] - 51s 769ms/step - loss: 2.1676 - accuracy: 0.3305\n",
            "Epoch 17/100\n",
            "66/66 [==============================] - 51s 773ms/step - loss: 2.0805 - accuracy: 0.3524\n",
            "Epoch 18/100\n",
            "66/66 [==============================] - 51s 772ms/step - loss: 1.9896 - accuracy: 0.3786\n",
            "Epoch 19/100\n",
            "66/66 [==============================] - 51s 777ms/step - loss: 1.8202 - accuracy: 0.4119\n",
            "Epoch 20/100\n",
            "66/66 [==============================] - 51s 775ms/step - loss: 1.7474 - accuracy: 0.4486\n",
            "Epoch 21/100\n",
            "66/66 [==============================] - 51s 779ms/step - loss: 1.5847 - accuracy: 0.4900\n",
            "Epoch 22/100\n",
            "66/66 [==============================] - 51s 777ms/step - loss: 1.5590 - accuracy: 0.5038\n",
            "Epoch 23/100\n",
            "66/66 [==============================] - 51s 780ms/step - loss: 1.5751 - accuracy: 0.5000\n",
            "Epoch 24/100\n",
            "66/66 [==============================] - 51s 777ms/step - loss: 1.2698 - accuracy: 0.5952\n",
            "Epoch 25/100\n",
            "66/66 [==============================] - 51s 774ms/step - loss: 1.1456 - accuracy: 0.6295\n",
            "Epoch 26/100\n",
            "66/66 [==============================] - 51s 776ms/step - loss: 0.9999 - accuracy: 0.6843\n",
            "Epoch 27/100\n",
            "66/66 [==============================] - 51s 772ms/step - loss: 0.9293 - accuracy: 0.6895\n",
            "Epoch 28/100\n",
            "66/66 [==============================] - 52s 781ms/step - loss: 0.8145 - accuracy: 0.7329\n",
            "Epoch 29/100\n",
            "66/66 [==============================] - 52s 786ms/step - loss: 0.6571 - accuracy: 0.7838\n",
            "Epoch 30/100\n",
            "66/66 [==============================] - 52s 782ms/step - loss: 0.5865 - accuracy: 0.8086\n",
            "Epoch 31/100\n",
            "66/66 [==============================] - 52s 785ms/step - loss: 0.5697 - accuracy: 0.8167\n",
            "Epoch 32/100\n",
            "66/66 [==============================] - 51s 780ms/step - loss: 0.5434 - accuracy: 0.8257\n",
            "Epoch 33/100\n",
            "66/66 [==============================] - 52s 781ms/step - loss: 0.4433 - accuracy: 0.8610\n",
            "Epoch 34/100\n",
            "66/66 [==============================] - 51s 772ms/step - loss: 0.3314 - accuracy: 0.8962\n",
            "Epoch 35/100\n",
            "66/66 [==============================] - 51s 778ms/step - loss: 0.3383 - accuracy: 0.8800\n",
            "Epoch 36/100\n",
            "66/66 [==============================] - 51s 776ms/step - loss: 0.4651 - accuracy: 0.8538\n",
            "Epoch 37/100\n",
            "66/66 [==============================] - 52s 780ms/step - loss: 0.3887 - accuracy: 0.8800\n",
            "Epoch 38/100\n",
            "66/66 [==============================] - 51s 775ms/step - loss: 0.3093 - accuracy: 0.8900\n",
            "Epoch 39/100\n",
            "66/66 [==============================] - 51s 776ms/step - loss: 0.3086 - accuracy: 0.8981\n",
            "Epoch 40/100\n",
            "66/66 [==============================] - 51s 779ms/step - loss: 0.2825 - accuracy: 0.9090\n",
            "Epoch 41/100\n",
            "66/66 [==============================] - 52s 781ms/step - loss: 0.2550 - accuracy: 0.9186\n",
            "Epoch 42/100\n",
            "66/66 [==============================] - 51s 778ms/step - loss: 0.2555 - accuracy: 0.9195\n",
            "Epoch 43/100\n",
            "66/66 [==============================] - 51s 776ms/step - loss: 0.2403 - accuracy: 0.9200\n",
            "Epoch 44/100\n",
            "66/66 [==============================] - 51s 776ms/step - loss: 0.1956 - accuracy: 0.9395\n",
            "Epoch 45/100\n",
            "66/66 [==============================] - 51s 778ms/step - loss: 0.1776 - accuracy: 0.9410\n",
            "Epoch 46/100\n",
            "66/66 [==============================] - 51s 778ms/step - loss: 0.1553 - accuracy: 0.9490\n",
            "Epoch 47/100\n",
            "66/66 [==============================] - 51s 780ms/step - loss: 0.1962 - accuracy: 0.9357\n",
            "Epoch 48/100\n",
            "66/66 [==============================] - 51s 771ms/step - loss: 0.1806 - accuracy: 0.9414\n",
            "Epoch 49/100\n",
            "66/66 [==============================] - 51s 772ms/step - loss: 0.2686 - accuracy: 0.9100\n",
            "Epoch 50/100\n",
            "66/66 [==============================] - 51s 769ms/step - loss: 0.2417 - accuracy: 0.9224\n",
            "Epoch 51/100\n",
            "66/66 [==============================] - 51s 768ms/step - loss: 0.2555 - accuracy: 0.9205\n",
            "Epoch 52/100\n",
            "66/66 [==============================] - 51s 776ms/step - loss: 0.2022 - accuracy: 0.9367\n",
            "Epoch 53/100\n",
            "66/66 [==============================] - 51s 772ms/step - loss: 0.1921 - accuracy: 0.9367\n",
            "Epoch 54/100\n",
            "66/66 [==============================] - 51s 777ms/step - loss: 0.1687 - accuracy: 0.9495\n",
            "Epoch 55/100\n",
            "66/66 [==============================] - 51s 774ms/step - loss: 0.1456 - accuracy: 0.9476\n",
            "Epoch 56/100\n",
            "66/66 [==============================] - 51s 774ms/step - loss: 0.1353 - accuracy: 0.9586\n",
            "Epoch 57/100\n",
            "66/66 [==============================] - 51s 778ms/step - loss: 0.1406 - accuracy: 0.9510\n",
            "Epoch 58/100\n",
            "66/66 [==============================] - 51s 776ms/step - loss: 0.1234 - accuracy: 0.9595\n",
            "Epoch 59/100\n",
            "66/66 [==============================] - 51s 773ms/step - loss: 0.1327 - accuracy: 0.9567\n",
            "Epoch 60/100\n",
            "66/66 [==============================] - 51s 776ms/step - loss: 0.1705 - accuracy: 0.9400\n",
            "Epoch 61/100\n",
            "66/66 [==============================] - 51s 776ms/step - loss: 0.1814 - accuracy: 0.9390\n",
            "Epoch 62/100\n",
            "66/66 [==============================] - 51s 773ms/step - loss: 0.1795 - accuracy: 0.9390\n",
            "Epoch 63/100\n",
            "66/66 [==============================] - 51s 774ms/step - loss: 0.1980 - accuracy: 0.9419\n",
            "Epoch 64/100\n",
            "66/66 [==============================] - 51s 776ms/step - loss: 0.1750 - accuracy: 0.9462\n",
            "Epoch 65/100\n",
            "66/66 [==============================] - 51s 769ms/step - loss: 0.1422 - accuracy: 0.9538\n",
            "Epoch 66/100\n",
            "66/66 [==============================] - 51s 775ms/step - loss: 0.1487 - accuracy: 0.9557\n",
            "Epoch 67/100\n",
            "66/66 [==============================] - 51s 770ms/step - loss: 0.1664 - accuracy: 0.9471\n",
            "Epoch 68/100\n",
            "66/66 [==============================] - 51s 776ms/step - loss: 0.1052 - accuracy: 0.9667\n",
            "Epoch 69/100\n",
            "66/66 [==============================] - 51s 770ms/step - loss: 0.1178 - accuracy: 0.9595\n",
            "Epoch 70/100\n",
            "66/66 [==============================] - 51s 774ms/step - loss: 0.1299 - accuracy: 0.9605\n",
            "Epoch 71/100\n",
            "66/66 [==============================] - 51s 771ms/step - loss: 0.1868 - accuracy: 0.9400\n",
            "Epoch 72/100\n",
            "66/66 [==============================] - 51s 771ms/step - loss: 0.1350 - accuracy: 0.9614\n",
            "Epoch 73/100\n",
            "66/66 [==============================] - 51s 770ms/step - loss: 0.1134 - accuracy: 0.9643\n",
            "Epoch 74/100\n",
            "66/66 [==============================] - 51s 775ms/step - loss: 0.0977 - accuracy: 0.9681\n",
            "Epoch 75/100\n",
            "66/66 [==============================] - 51s 770ms/step - loss: 0.1508 - accuracy: 0.9529\n",
            "Epoch 76/100\n",
            "66/66 [==============================] - 51s 769ms/step - loss: 0.1456 - accuracy: 0.9519\n",
            "Epoch 77/100\n",
            "66/66 [==============================] - 51s 768ms/step - loss: 0.1444 - accuracy: 0.9605\n",
            "Epoch 78/100\n",
            "66/66 [==============================] - 51s 768ms/step - loss: 0.1589 - accuracy: 0.9486\n",
            "Epoch 79/100\n",
            "66/66 [==============================] - 51s 767ms/step - loss: 0.1348 - accuracy: 0.9548\n",
            "Epoch 80/100\n",
            "66/66 [==============================] - 51s 773ms/step - loss: 0.1526 - accuracy: 0.9524\n",
            "Epoch 81/100\n",
            "66/66 [==============================] - 51s 777ms/step - loss: 0.1485 - accuracy: 0.9524\n",
            "Epoch 82/100\n",
            "66/66 [==============================] - 51s 773ms/step - loss: 0.1448 - accuracy: 0.9519\n",
            "Epoch 83/100\n",
            "66/66 [==============================] - 51s 766ms/step - loss: 0.1403 - accuracy: 0.9543\n",
            "Epoch 84/100\n",
            "66/66 [==============================] - 50s 762ms/step - loss: 0.1280 - accuracy: 0.9581\n",
            "Epoch 85/100\n",
            "66/66 [==============================] - 51s 773ms/step - loss: 0.0939 - accuracy: 0.9729\n",
            "Epoch 86/100\n",
            "66/66 [==============================] - 50s 762ms/step - loss: 0.0845 - accuracy: 0.9710\n",
            "Epoch 87/100\n",
            "66/66 [==============================] - 50s 763ms/step - loss: 0.0815 - accuracy: 0.9738\n",
            "Epoch 88/100\n",
            "66/66 [==============================] - 51s 771ms/step - loss: 0.0909 - accuracy: 0.9714\n",
            "Epoch 89/100\n",
            "66/66 [==============================] - 51s 766ms/step - loss: 0.1232 - accuracy: 0.9624\n",
            "Epoch 90/100\n",
            "66/66 [==============================] - 50s 761ms/step - loss: 0.1447 - accuracy: 0.9586\n",
            "Epoch 91/100\n",
            "66/66 [==============================] - 51s 767ms/step - loss: 0.1412 - accuracy: 0.9500\n",
            "Epoch 92/100\n",
            "66/66 [==============================] - 51s 779ms/step - loss: 0.1171 - accuracy: 0.9610\n",
            "Epoch 93/100\n",
            "66/66 [==============================] - 51s 768ms/step - loss: 0.1687 - accuracy: 0.9481\n",
            "Epoch 94/100\n",
            "66/66 [==============================] - 51s 775ms/step - loss: 0.1250 - accuracy: 0.9619\n",
            "Epoch 95/100\n",
            "66/66 [==============================] - 51s 777ms/step - loss: 0.1285 - accuracy: 0.9538\n",
            "Epoch 96/100\n",
            "66/66 [==============================] - 51s 768ms/step - loss: 0.1212 - accuracy: 0.9619\n",
            "Epoch 97/100\n",
            "66/66 [==============================] - 50s 765ms/step - loss: 0.1857 - accuracy: 0.9486\n",
            "Epoch 98/100\n",
            "66/66 [==============================] - 51s 770ms/step - loss: 0.2731 - accuracy: 0.9195\n",
            "Epoch 99/100\n",
            "66/66 [==============================] - 50s 765ms/step - loss: 0.2192 - accuracy: 0.9276\n",
            "Epoch 100/100\n",
            "66/66 [==============================] - 51s 767ms/step - loss: 0.1856 - accuracy: 0.9348\n",
            "54/54 [==============================] - 11s 189ms/step - loss: 7.3818 - accuracy: 0.2058\n",
            "Training Runtime:  01:25:11\n",
            "The Test Set Loss is:  7.381809711456299 \n",
            "The Test Set Accuracy is:  0.2058309018611908\n",
            "54/54 [==============================] - 11s 195ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model to local path\n",
        "\n",
        "model.save('/content/drive/MyDrive/AIStuff/myymodel')"
      ],
      "metadata": {
        "id": "SZimkUw4nG92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok==4.2.2\n",
        "!pip install tensorflow\n",
        "!pip install numpy\n",
        "!pip install Pillow\n",
        "!pip install requests\n",
        "!pip install -U ipykernel\n",
        "!pip install -q streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "IJQBrOVjOHWq",
        "outputId": "ad2ebae5-d223-4da7-fd44-9e5e1e1c25e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok==4.2.2\n",
            "  Downloading pyngrok-4.2.2.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pyngrok==4.2.2) (0.18.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok==4.2.2) (6.0.1)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-4.2.2-py3-none-any.whl size=18016 sha256=e80d3032836a01254443d55199881a346f9a6e3268a93145fb0acde44d9b9508\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/ae/38/d5c5d22cec6ab0169b667c91ae35c400e961cc25e382a4c3ce\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "  Attempting uninstall: pyngrok\n",
            "    Found existing installation: pyngrok 7.0.3\n",
            "    Uninstalling pyngrok-7.0.3:\n",
            "      Successfully uninstalled pyngrok-7.0.3\n",
            "Successfully installed pyngrok-4.2.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyngrok"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile score.py\n",
        "\n",
        "# script that sets up ngrok app's user interface through streamline\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "#hola\n",
        "st.title(\"Dog Image Classifier\")\n",
        "st.text(\"Provide URL of dog Image for image classification\")\n",
        "\n",
        "def load_model():\n",
        "    model = tf.keras.models.load_model('/content/drive/MyDrive/AIStuff/myymodel')\n",
        "    return model\n",
        "\n",
        "with st.spinner('Loading Model Into Memory...'):\n",
        "  model = load_model()\n",
        "\n",
        "classes=['n02085620-chihuahua', 'n02085782-japanese_spaniel', 'n02085936-maltese_dog', 'n02086079-pekinese', 'n02086240-shih-tzu', 'n02086646-blenheim_spaniel', 'n02086910-papillon', 'n02087046-toy_terrier', 'n02087394-rhodesian_ridgeback', 'n02088094-afghan_hound', 'n02088238-basset', 'n02088364-beagle', 'n02088466-bloodhound', 'n02088632-bluetick', 'n02089078-black-and-tan_coonhound', 'n02089867-walker_hound', 'n02089973-english_foxhound', 'n02090379-redbone', 'n02090622-borzoi', 'n02090721-irish_wolfhound', 'n02091032-italian_greyhound', 'n02091134-whippet', 'n02091244-ibizan_hound', 'n02091467-norwegian_elkhound', 'n02091635-otterhound', 'n02091831-saluki', 'n02092002-scottish_deerhound', 'n02092339-weimaraner', 'n02093256-staffordshire_bullterrier', 'n02093428-american_staffordshire_terrier', 'n02093647-bedlington_terrier', 'n02093754-border_terrier', 'n02093859-kerry_blue_terrier', 'n02093991-irish_terrier', 'n02094114-norfolk_terrier', 'n02094258-norwich_terrier', 'n02094433-yorkshire_terrier', 'n02095314-wire-haired_fox_terrier', 'n02095570-lakeland_terrier', 'n02095889-sealyham_terrier', 'n02096051-airedale', 'n02096177-cairn', 'n02096294-australian_terrier', 'n02096437-dandie_dinmont', 'n02096585-boston_bull', 'n02097047-miniature_schnauzer', 'n02097130-giant_schnauzer', 'n02097209-standard_schnauzer', 'n02097298-scotch_terrier', 'n02097474-tibetan_terrier', 'n02097658-silky_terrier', 'n02098105-soft-coated_wheaten_terrier', 'n02098286-west_highland_white_terrier', 'n02098413-lhasa', 'n02099267-flat-coated_retriever', 'n02099429-curly-coated_retriever', 'n02099601-golden_retriever', 'n02099712-labrador_retriever', 'n02099849-chesapeake_bay_retriever', 'n02100236-german_short-haired_pointer', 'n02100583-vizsla', 'n02100735-english_setter', 'n02100877-irish_setter', 'n02101006-gordon_setter', 'n02101388-brittany_spaniel', 'n02101556-clumber', 'n02102040-english_springer', 'n02102177-welsh_springer_spaniel', 'n02102318-cocker_spaniel', 'n02102480-sussex_spaniel', 'n02102973-irish_water_spaniel', 'n02104029-kuvasz', 'n02104365-schipperke', 'n02105056-groenendael', 'n02105162-malinois', 'n02105251-briard', 'n02105412-kelpie', 'n02105505-komondor', 'n02105641-old_english_sheepdog', 'n02105855-shetland_sheepdog', 'n02106030-collie', 'n02106166-border_collie', 'n02106382-bouvier_des_flandres', 'n02106550-rottweiler', 'n02106662-german_shepherd', 'n02107142-doberman', 'n02107312-miniature_pinscher', 'n02107574-greater_swiss_mountain_dog', 'n02107683-bernese_mountain_dog', 'n02107908-appenzeller', 'n02108000-entlebucher', 'n02108089-boxer', 'n02108422-bull_mastiff', 'n02108551-tibetan_mastiff', 'n02108915-french_bulldog', 'n02109047-great_dane', 'n02109525-saint_bernard', 'n02109961-eskimo_dog', 'n02110063-malamute', 'n02110185-siberian_husky', 'n02110627-affenpinscher', 'n02110806-basenji', 'n02110958-pug', 'n02111129-leonberg', 'n02111277-newfoundland', 'n02111500-great_pyrenees', 'n02111889-samoyed', 'n02112018-pomeranian', 'n02112137-chow', 'n02112350-keeshond', 'n02112706-brabancon_griffon', 'n02113023-pembroke', 'n02113186-cardigan', 'n02113624-toy_poodle', 'n02113712-miniature_poodle', 'n02113799-standard_poodle', 'n02113978-mexican_hairless', 'n02115641-dingo', 'n02115913-dhole', 'n02116738-african_hunting_dog']\n",
        "\n",
        "def scale(image):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image /= 255.0\n",
        "    return tf.image.resize(image, [227, 227])\n",
        "\n",
        "def decode_img(image):\n",
        "    img = tf.image.decode_jpeg(image, channels=3)\n",
        "    img = scale(img)\n",
        "    return np.expand_dims(img, axis=0)\n",
        "\n",
        "path = st.text_input('Enter Image URL to Classify..', 'https://www.akc.org/wp-content/uploads/2017/11/Chihuahua-standing-in-three-quarter-view.jpg')\n",
        "\n",
        "if path is not None:\n",
        "    content = requests.get(path).content  # Get image content\n",
        "    image = decode_img(content)  # Process the image\n",
        "\n",
        "    st.write(\"Predicted Class:\")\n",
        "    with st.spinner('classifying.....'):\n",
        "        label = np.argmax(model.predict(image), axis=1)\n",
        "        st.write(classes[label[0]])\n",
        "\n",
        "    st.write(\"\")\n",
        "    image_display = Image.open(BytesIO(content))\n",
        "    st.image(image_display, caption='Classifying Dog Image', use_column_width=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qO_0SfdDvl-",
        "outputId": "10f7b99e-3eb7-4c26-ac4e-88a8ca0ee83a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing score.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup streamlit run score.py &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yjw_omt-FA5L",
        "outputId": "2389f51f-4ba2-47cc-f50c-bac3262d4ec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "url = ngrok.connect(port=8501)\n",
        "url"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "ba542P-7E-VY",
        "outputId": "64ebdf3f-2336-4d16-cada-9ce165affa6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-12-13T00:56:06+0000 lvl=warn msg=\"invalid tunnel configuration\" pg=/api/tunnels id=bb1cb480b646a94c err=\"yaml: unmarshal errors:\\n  line 1: field port not found in type config.HTTPv2Tunnel\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "PyngrokNgrokHTTPError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(url, method, data, params, timeout, auth)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    635\u001b[0m                 'http', request, response, code, msg, hdrs)\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 400: Bad Request",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mPyngrokNgrokHTTPError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-a9250ce4cbea>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyngrok\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mngrok\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8501\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(addr, proto, name, pyngrok_config, **options)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngrok_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapi_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \"\"\"\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(url, method, data, params, timeout, auth)\u001b[0m\n",
            "\u001b[0;31mPyngrokNgrokHTTPError\u001b[0m: ngrok client exception, API returned 400: {\"error_code\":102,\"status_code\":400,\"msg\":\"invalid tunnel configuration\",\"details\":{\"err\":\"yaml: unmarshal errors:\\n  line 1: field port not found in type config.HTTPv2Tunnel\"}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat nohup.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NE0zd-8yWzNi",
        "outputId": "7b8d8256-57fb-41ac-f516-d4e1ed28852e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\n",
            "\n",
            "  You can now view your Streamlit app in your browser.\n",
            "\n",
            "  Network URL: http://172.28.0.12:8548\n",
            "  External URL: http://35.245.228.38:8548\n",
            "\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\n",
            "\n",
            "  You can now view your Streamlit app in your browser.\n",
            "\n",
            "  Network URL: http://172.28.0.12:8549\n",
            "  External URL: http://35.245.228.38:8549\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Personal Auth Token from Ngrok user account\n",
        "!ngrok authtoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvcQc5I4SRy2",
        "outputId": "4ce56048-c1af-4f5c-ac5c-2ec5d63f8d16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import time\n",
        "\n",
        "# Start time\n",
        "start_time = time.time()\n",
        "\n",
        "# Replace 'SERVER_ENDPOINT' and 'URL_TO_YOUR_IMAGE' with your server's endpoint and image URL\n",
        "server_endpoint = 'https://8161-35-245-228-38.ngrok-free.app/'\n",
        "image_url = 'https://cdn.britannica.com/16/234216-050-C66F8665/beagle-hound-dog.jpg'\n",
        "\n",
        "# Send image to server\n",
        "response = requests.post(server_endpoint, json={'image_url': image_url})\n",
        "\n",
        "# End time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate latency\n",
        "latency = end_time - start_time\n",
        "print(f\"Latency: {latency} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thUOBCpa-B9a",
        "outputId": "81476a30-31a3-4249-8c88-5fd11a9ec838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latency: 0.23293352127075195 seconds\n"
          ]
        }
      ]
    }
  ]
}